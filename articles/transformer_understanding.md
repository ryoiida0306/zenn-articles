---
title: "【備忘録】Transformerの理解を深める"
emoji: "🤖"
type: "tech"
topics: ["AI", "自然言語処理", "Transformer"]
published: false
---

# Transformerとは何か

![Transformer](/images/articles/transformer_understanding/transformer.png)

Transformerの提案された論文のタイトルは、「Attention is All You Need」というものです。
名の通り、Attention機構がTransformerの中心的な役割を果たしています。
従来は系列データを処理する際にRNNやLSTMが使われていましたが、
Transformerは、並列計算ができるAttention機構を使って、系列データを処理するモデルです。
並列計算ができるので、計算量が系列長に依存せずに高速であるという特徴があります。
しかも、RNNやLSTMと比べて性能が高いことが実証されています。

Transformerが提案された初期では、自然言語処理のタスクに使われることが多かったですが、
Attention機構の特性が非常に強力であるため、現在ではTransformerをエンコーダ単体やデコーダ単体として使うことも多いです。
例えば、画像認識のタスクにもTransformerが使われることがあります。

この記事では、Transformerについて理解を深めるため、様々な観点から解説していきます。


# Atteinton機構

Attentionとは、入力系列の各要素に対して、出力系列の各要素がどの程度注目しているかを表す重みのことです。

入力系列　This apple is very ripe, so it is sweet.
出力系列　このりんごはとても熟しているので、甘いです。
![Attention](/images/articles/transformer_understanding/attention.png)

英語から日本語への翻訳タスクを例にとって説明します。
例えば、「りんご」という単語を出力する際に、入力系列のどの単語に注目すれば良いかを
考えると、入力系列の「apple」という単語に注目すべきです。
このように、Attention機構は、入力系列の各要素に対して、出力系列の各要素がどの程度注目しているかを表す重みを計算します。
（言い方を変えると、どの程度注目するべきかという情報を学習させます。）

ここで1つ抑えたいのは、「りんご」は「apple」という単語以外にも、「ripe」や「sweet」という単語にも注目すれば、
より正確な理解が出来そうだということです。
翻訳する際に「りんご」という単語の中に「apple」,「ripe」,「sweet」の情報を含めると、
この文における「りんご」は、「熟していて甘いりんご」、というより正確なりんごのイメージを持つことができます。
これがアテンションの強力なところです。
式で表すと以下の通りになります。

$$
\bm{v}_{\text{りんご}} = \sum_{l \in \bm{L}} \bm{w}_{l \rightarrow \text{りんご}} \cdot \bm{v}_l
$$

（$\bm{l}$は入力系列、$\bm{v}$は単語のベクトルを表し、$\bm{w}_{\text{単語1} \rightarrow \text{単語2}}$は単語1から単語2へのアテンション重みを表します。）
$\bm{w}_{\text{apple} \rightarrow \text{りんご}}$、$\bm{w}_{\text{ripe} \rightarrow \text{りんご}}$、$\bm{w}_{\text{sweet} \rightarrow \text{りんご}}$が大きいことが期待できます。

ここで発展的な発想として、入力系列も日本語にしてみましょう。

入力系列　このりんごはとても熟しているので、甘いです。
出力系列　このりんごはとても熟しているので、甘いです。
![Attention](/images/articles/transformer_understanding/attention2.png)

この場合でも、同様に「りんご」という単語を出力する際に、入力系列の「りんご」、「熟している」、「甘い」に注目されれば、
正確なりんごへのイメージを高めることができます。

このように、Attention機構は、入力系列と出力系列が同じであっても違っても、情報がより洗練された形で伝わるようになります。
また、入力系列と出力系列が異なるとき、cross-attentionと呼ばれ、
同じであるとき、self-attentionと呼ばれます。

つまり、cross-attentionは、入力系列と出力系列の要素同士の対応関係を持たせるために使われ、
self-attentionは、自分自身の情報をより洗練された形へアップグレードするために使われます。

## masked self-attention
Transformerでは、デコーダのself-attentionにおいて、未来の情報を見ないようにするために、
masked self-attentionという手法が使われています。
文章生成タスクでは、今生成されている単語系列を用いて次の単語を推論する必要があります。
そのため、次の単語にマスクをして学習されます。
(文章生成タスクでは、翻訳タスクと違い、入力系列と出力系列の言語が同じであるため、マスクをしないと
答えを見ながら予測することになるため、ボトルネックが発生せずに学習がうまく進みません。)




## Attentionマップ
ここではself-attentionとして説明します。

Attentionは一般的にAttentionマップという形で可視化されます。

![Attention Map](/images/articles/transformer_understanding/attention_map.png)

この図は、入力系列の各単語に対して、出力系列の各単語がどの程度注目しているかを表しています。
例えば、出力系列の「りんご」に注目すると、入力系列の「apple」に多く注目しており、重みが大きいことがわかります。
また別に「ripe」や「sweet」にも少なからず注目していることがわかります。

ここでAttention機構の式を見てみましょう。

$$
Attention(Q, K, V) = \text{softmax}(\frac{QK^T}{\sqrt{d_k}})V\\
Q = XW^Q, K = XW^K, V = XW^V
$$

式だけ見てもわかりにくいため、説明していきます。

まず、$Q, K, V$はそれぞれクエリ、キー、バリューを表します。
また、$X$は入力系列の各単語のベクトルを表し、$W^Q, W^K, W^V$は学習によって調節される、キュー、キー、バリューそれぞれの重み行列を表します。

$Q$のクエリは、各単語がどんな情報を持つかという問いかけの情報を表します。
$K$のキーは、各単語がどんな情報を持つかという問いかけに対する答えを表します。
$V$のバリューは、各単語そのものの情報を表します。（実際は$W^V$を工夫して掛けることで$X$の次元を落として再度元の次元に戻すことで、重要な情報のみを残すようにします）

Attentionの式における内積$QK^T$は、クエリとキーの内積を計算し、関連度を計算します。
これにより、各単語がどれほど重要であるかを計算することができます。
また、$\sqrt{d_k}$で割る事は、内積の値が大きくなりすぎないようにするための正規化の役割を果たしますが、
本題とそれるため、詳細は割愛します。
その後softmax関数を通すことで、各単語の重要度の合計が1になるように正規化します。
これがアテンション重みに対応します。
最後に、バリューにアテンション重みをかけて、各単語の重要度を考慮した情報を計算します。

このように、Attention機構は、入力系列の各単語に対して、出力系列の各単語がどの程度注目しているかを表す重みを計算し、
その重みを使って、出力系列の各単語の情報を計算します。

ここでの疑問点として、キュー、キー、バリューは、すべて$X$から計算されることは不思議に思えるかもしれません。
実際キューは、問いかけの情報を持つかどうかはわかりませんが、そのように想定しながら損失関数を設定し、最小化することによって
キューが問いかけの情報を持つように学習されます。キーやバリューも同様です。

なので次のようなとらえ方をすることもできます。
キューは、$X$自体を$W^Q$という回転行列に通すことによって見方を変えたもの
キーは、$X$自体を$W^K$という回転行列に通すことによってまた違う見方をしたもの

この考え方をすると、内積の計算は、それぞれ違うとらえ方をした時にどれだけ重なっているかを計算していると考えることができます。

![Attention Map](/images/articles/transformer_understanding/attention_map2.png) ;;self-attentionの例
![Attention Map](/images/articles/transformer_understanding/attention_map3.png) ;;cross-attentionの例
![Attention Map](/images/articles/transformer_understanding/attention_map4.png) ;;masked self-attentionの例


## Multi-Head Attention
Transformerでは、Attention機構を複数のヘッドに分割して計算するMulti-Head Attentionという手法が使われています。

具体的には、$h$個のヘッドを持つMulti-Head Attentionの式は以下の通りです。

$$
\text{MultiHead}(Q, K, V) = \text{Concat}(\text{head}_1, \text{head}_2, \ldots, \text{head}_h)W^O\\
\text{head}_i = \text{Attention}(QW_i^Q, KW_i^K, VW_i^V)
$$

ここで、$W_i^Q, W_i^K, W_i^V$はそれぞれ、$i$番目のヘッドの重み行列を表します。
また、$W^O$はMulti-Head Attentionの出力の重み行列を表します。

このように、Multi-Head Attentionでは、複数のヘッドでそれぞれAttentionを計算し、その結果を結合して出力します。
それぞれのヘッドでは、重み行列自体も個別に管理されるため、それぞれ異なる見方をして、
「この見方はどうか」、「こっちの見方だとどうだ」と様々な視点から試し、
最終的にそれぞれのヘッドの結果を結合して出力することで、より豊かな情報を得ることができます。

#翻訳タスク(エンコーダ・デコーダ)
翻訳タスクはTransformerの本来の使われ方で、
エンコーダとデコーダをセットで使います。

![Translation](/images/articles/transformer_understanding/translation.png)

ここでも英語から日本語への翻訳タスクを例にとって説明します。

エンコーダへの入力は英語の文、デコーダへの入力はこれまでに生成された日本語の文、
そしてデコーダの出力は次に生成する日本語の1単語です。

より正確には、エンコーダやデコーダでの文の入力は、入力における分の長さを考慮する次元を$N$とすると、
最後に予測した$N$個の単語をembeddingし、位置情報を付与するための位置エンコーディングを加えたものを入力とします。
またデコーダの出力は、語彙サイズの次元を持つベクトルで、各語彙が出力する確率をsoftmax関数を通すことで得られたものです。

cross-attentionでは、系列同士の要素の対応関係を持たせるために使われ、
self-attentionでは、自分自身の情報をより洗練された形へアップグレードするために使われますが、
翻訳タスクではこれら二つを組み合わせて使います。

エンコーダやデコーダでself-attentionを使うことで、
入力系列や出力系列自身をアップグレードし、
途中でcross-attentionを使うことで、
入力系列と出力系列の要素同士の対応関係を持たせることができます。

デコーダ後の線形層線形層では、文全体の情報をもとに各語彙ごとの重要度に
分けるように射影を行います。
その後、softmax関数を通すことで、各語彙が出力する確率を得ることができます。

このように、エンコーダとデコーダをセットで使うことで、
翻訳タスクを行うことができます。

# 文章生成タスク(デコーダのみ)

文章生成タスクでは、Transformerの元の構造のデコーダのみを使います。

![Sentence Generation](/images/articles/transformer_understanding/sentence_generation.png)

デコーダにはmasked self-attentionが使われており、未来を見ないようにして学習されることによって、
文章生成タスクに適したモデルとなっています。

デコーダへの入力はこれまで生成された文章の系列
そしてデコーダの出力は生成する次単語の各語彙の確率です。


# 要約タスク等(エンコーダのみ)

自己要約タスクでは、Transformerの元の構造のエンコーダのみを使います。

![Self-Summarization](/images/articles/transformer_understanding/self_summarization.png)

これは単にself-attentionを使って、入力系列の情報をより洗練された形にアップグレードするだけです。

このself-attention飲みの構造でも優れているため音声認識や画像認識など、自然言語処理以外のタスクにも適用できます。

1つ特殊な使われ方をする例を紹介すると、ViT(Vision Transformer)というモデルがあります。
これは画像認識タスクであり、入力される画像を要約するためのタスクです。
入力は画像のピクセル情報で、出力は画像のクラスラベルです。
しかし入力はピクセルに加えて、空の要素を追加して、self-attentionを通し、その空の要素に他のピクセルの情報を集約することで、
画像全体の情報を要約することができます。詳しくはViTの記事を参照してください。

# まとめ

Attention機構にAttentionしましょう！！


# 理解をさらに深めるメモ

- 翻訳タスクにおいて$V$が翻訳元である理由は、推論時には翻訳先の分が未知であるため、
  翻訳元の情報を使って翻訳先の情報を生成する必要があるため。それ以外でも、翻訳先の情報を使ってしまうと
  ボトルネックが発生しないから。
- $Q$と$K$の回転行列である$W^Q$と$W^K$を用いて、いろんな見方をするというのは具体的に次の図のようなことだと思う。
    ![Attention Map](/images/articles/transformer_understanding/attention_map5.png)
- 文章生成タスクでは仮に回転行列$W^Q$と$W^K$が単位行列であるとき、最大になってしまい、学習に意味がなくなってしまうのでは、と考えてしまうが、
  別に、$QK^T$の値自体を大きくすることを目的としているわけではない。単位行列であるときは自分自身の単語にしか注目しなくなるため、
  文章全体としてアップグレードできなくなる。そうすると次の単語を予測することができなくなる。よって、損失が高くなるので、
  単位行列にはならない。
  





